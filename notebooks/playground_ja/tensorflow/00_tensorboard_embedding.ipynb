{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "## 事前準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_PATH = \"/root/tmp/tensorboard/mnist\"\n",
    "DATA_PATH = os.path.join(os.getcwd(), \"mnist/data/\")\n",
    "LABELS_PATH = os.path.join(os.getcwd(), \"mnist/labels_1024.tsv\")\n",
    "SPRITE_PATH = os.path.join(os.getcwd(), \"mnist/sprite_1024.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/notebooks/playground_ja/tensorflow/mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting /root/notebooks/playground_ja/tensorflow/mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /root/notebooks/playground_ja/tensorflow/mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /root/notebooks/playground_ja/tensorflow/mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.contrib.learn.datasets.mnist.read_data_sets(train_dir=DATA_PATH, one_hot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer definition\n",
    "\n",
    "### Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(input, channels_in, channels_out, name=\"conv\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([5, 5, channels_in, channels_out], stddev=0.1), name=\"w\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[channels_out]), name=\"b\")\n",
    "        conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        a = tf.nn.relu(conv + b)\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", a)\n",
    "        return a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_layer(input, channels_in, channels_out, name=\"fc\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([channels_in, channels_out], stddev=0.1), name=\"w\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[channels_out]), name=\"b\")\n",
    "        a = tf.matmul(input, w) + b\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", a)\n",
    "        return a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-Forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup placeholders, and reshape the data\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784], name=\"images\")\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10], name=\"labels\")\n",
    "\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "tf.summary.image('input', x_image, 3)\n",
    "\n",
    "# Create the network\n",
    "conv1 = conv_layer(x_image, 1, 32, \"conv1\")\n",
    "pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "conv2 = conv_layer(pool1, 32, 64, \"conv2\")\n",
    "pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "flattened = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "fc1 = fc_layer(flattened, 7 * 7 * 64, 1024, \"fc1\")\n",
    "\n",
    "fc2 = fc_layer(fc1, 1024, 10, \"fc2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cross entropy as loss function\n",
    "with tf.name_scope(\"loss\"):\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits=fc2, labels=y)\n",
    "    )\n",
    "    tf.summary.scalar(\"cross_entropy\", cross_entropy)\n",
    "\n",
    "# use the AdamOptimizer to train the network\n",
    "with tf.name_scope(\"train\"):\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# compute the accuracy\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    prediction = tf.equal(tf.argmax(fc2, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "embedding = tf.Variable(tf.zeros([1024, 7 * 7 * 64]), name=\"embedding\")\n",
    "assignment = embedding.assign(flattened)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "writer = tf.summary.FileWriter(LOG_PATH)\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "embedding_config = config.embeddings.add()\n",
    "embedding_config.tensor_name = embedding.name\n",
    "embedding_config.sprite.image_path = SPRITE_PATH\n",
    "embedding_config.metadata_path = LABELS_PATH\n",
    "embedding_config.sprite.single_image_dim.extend([28, 28])\n",
    "\n",
    "tf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 train accuracy 0.1\n",
      "step 10 train accuracy 0.23\n",
      "step 20 train accuracy 0.3\n",
      "step 30 train accuracy 0.39\n",
      "step 40 train accuracy 0.67\n",
      "step 50 train accuracy 0.71\n",
      "step 60 train accuracy 0.81\n",
      "step 70 train accuracy 0.75\n",
      "step 80 train accuracy 0.77\n",
      "step 90 train accuracy 0.84\n",
      "step 100 train accuracy 0.92\n",
      "step 110 train accuracy 0.87\n",
      "step 120 train accuracy 0.85\n",
      "step 130 train accuracy 0.87\n",
      "step 140 train accuracy 0.94\n",
      "step 150 train accuracy 0.89\n",
      "step 160 train accuracy 0.91\n",
      "step 170 train accuracy 0.85\n",
      "step 180 train accuracy 0.88\n",
      "step 190 train accuracy 0.93\n",
      "step 200 train accuracy 0.84\n",
      "step 210 train accuracy 0.93\n",
      "step 220 train accuracy 0.98\n",
      "step 230 train accuracy 0.89\n",
      "step 240 train accuracy 0.94\n",
      "step 250 train accuracy 0.9\n",
      "step 260 train accuracy 0.93\n",
      "step 270 train accuracy 0.94\n",
      "step 280 train accuracy 0.91\n",
      "step 290 train accuracy 0.94\n"
     ]
    }
   ],
   "source": [
    "for i in range(300):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        [train_accuracy, summary] = sess.run([accuracy, merged_summary], feed_dict={\n",
    "            x: batch[0],\n",
    "            y: batch[1]\n",
    "        })\n",
    "        writer.add_summary(summary, i)\n",
    "        print(\"step %d train accuracy %g\" % (i, train_accuracy))\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        sess.run(\n",
    "            assignment,\n",
    "            feed_dict={\n",
    "                x: mnist.test.images[:1024],\n",
    "                y: mnist.test.labels[:1024]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        saver.save(sess, os.path.join(LOG_PATH, \"model.ckpt\"), i)\n",
    "\n",
    "    sess.run(train_step, feed_dict={\n",
    "        x: batch[0],\n",
    "        y: batch[1]\n",
    "    })\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
